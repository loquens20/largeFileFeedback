#!/usr/bin/env python3
"""
ì‹¤ì „ ì‚¬ìš© ì˜ˆì œ ëª¨ìŒ
ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì½”ë“œ ì˜ˆì œ
"""

import os
from integrated_processor import IntegratedProcessor
from llm_large_file_processor import ModelPricing


def example_1_simple_summary():
    """ì˜ˆì œ 1: ê°€ì¥ ê°„ë‹¨í•œ ë¬¸ì„œ ìš”ì•½"""
    print("\n" + "="*70)
    print("ì˜ˆì œ 1: ê°„ë‹¨í•œ ë¬¸ì„œ ìš”ì•½")
    print("="*70)

    from anthropic import Anthropic

    processor = IntegratedProcessor(
        api_client=Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
    )

    state = processor.process_file(
        file_path="document.pdf",
        system_prompt="ë‹¹ì‹ ì€ ìš”ì•½ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
        user_prompt_template="ë‹¤ìŒ ë‚´ìš©ì„ 3-5 ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½:\n{chunk_text}",
        model="claude-haiku-4",
        output_tokens=500
    )

    print(f"ì™„ë£Œ! ì´ ë¹„ìš©: ${state.total_cost:.2f}")


def example_2_cost_optimization():
    """ì˜ˆì œ 2: ë¹„ìš© ìµœì í™” ì „ëµ"""
    print("\n" + "="*70)
    print("ì˜ˆì œ 2: ë¹„ìš© ìµœì í™”")
    print("="*70)

    processor = IntegratedProcessor(api_client=None)  # ë°ëª¨ ëª¨ë“œ

    # 1ë‹¨ê³„: ì²­í¬ ìƒì„± (ë¬´ë£Œ)
    print("\n1ë‹¨ê³„: ì²­í¬ ìƒì„± ë° ë¹„ìš© ì˜ˆì¸¡")
    chunks = processor.preprocess_and_chunk("large_file.pdf")

    # 2ë‹¨ê³„: ë¹„ìš© ë¹„êµ
    print("\n2ë‹¨ê³„: ëª¨ë¸ë³„ ë¹„ìš© ë¹„êµ")
    total_tokens = sum(c.token_estimate for c in chunks)
    output_per_chunk = 1000

    costs = ModelPricing.compare_models(
        total_tokens,
        len(chunks) * output_per_chunk
    )

    cheapest = min(costs.items(), key=lambda x: x[1])
    most_expensive = max(costs.items(), key=lambda x: x[1])

    print(f"\nê°€ì¥ ì €ë ´: {cheapest[0]} (${cheapest[1]:.2f})")
    print(f"ê°€ì¥ ë¹„ì‹¼: {most_expensive[0]} (${most_expensive[1]:.2f})")
    print(f"ì ˆì•½ ê°€ëŠ¥: ${most_expensive[1] - cheapest[1]:.2f} "
          f"({(most_expensive[1] - cheapest[1]) / most_expensive[1] * 100:.1f}%)")

    # 3ë‹¨ê³„: ì €ë ´í•œ ëª¨ë¸ë¡œ ì²˜ë¦¬ ê²°ì •
    print(f"\n3ë‹¨ê³„: {cheapest[0]} ëª¨ë¸ë¡œ ì²˜ë¦¬ ì‹œì‘")
    print("(ì‹¤ì œ API í‚¤ê°€ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ process_file í˜¸ì¶œ)")


def example_3_progressive_quality():
    """ì˜ˆì œ 3: ì ì§„ì  í’ˆì§ˆ í–¥ìƒ"""
    print("\n" + "="*70)
    print("ì˜ˆì œ 3: ì ì§„ì  í’ˆì§ˆ í–¥ìƒ")
    print("="*70)

    processor = IntegratedProcessor(api_client=None)

    # Phase 1: ë¹ ë¥¸ ì´ˆì•ˆ
    print("\nPhase 1: ë¹ ë¥¸ ì´ˆì•ˆ (gpt-4o-mini)")
    state1 = processor.process_file(
        file_path="test_small.txt",
        system_prompt="ê°„ë‹¨íˆ ìš”ì•½í•˜ì„¸ìš”",
        user_prompt_template="{chunk_text}",
        model="gpt-4o-mini",
        output_tokens=300,
        auto_confirm=True
    )

    print(f"Phase 1 ì™„ë£Œ. ë¹„ìš©: ${state1.total_cost:.4f}")

    # ê²°ê³¼ ê²€í†  (ì‹¤ì œë¡œëŠ” ì‚¬ìš©ìê°€ í™•ì¸)
    print("\nê²°ê³¼ë¥¼ ê²€í† í•©ë‹ˆë‹¤...")
    print("ë§Œì¡±ìŠ¤ëŸ½ì§€ ì•Šë‹¤ë©´ Phase 2ë¡œ ì´ë™")

    # Phase 2: ê³ í’ˆì§ˆ ë¶„ì„ (í•„ìš”ì‹œ)
    print("\nPhase 2: ê³ í’ˆì§ˆ ë¶„ì„ (claude-sonnet-4)")
    state2 = processor.process_file(
        file_path="test_small.txt",
        system_prompt="ìì„¸í•˜ê³  ì •í™•í•˜ê²Œ ë¶„ì„í•˜ì„¸ìš”",
        user_prompt_template="{chunk_text}",
        model="claude-sonnet-4",
        output_tokens=1000,
        auto_confirm=True
    )

    print(f"Phase 2 ì™„ë£Œ. ë¹„ìš©: ${state2.total_cost:.4f}")
    print(f"ì´ ë¹„ìš©: ${state1.total_cost + state2.total_cost:.4f}")


def example_4_pause_resume():
    """ì˜ˆì œ 4: ì¼ì‹œì •ì§€ ë° ì¬ê°œ"""
    print("\n" + "="*70)
    print("ì˜ˆì œ 4: ì¼ì‹œì •ì§€ ë° ì¬ê°œ")
    print("="*70)

    import threading
    import time

    processor = IntegratedProcessor(api_client=None)

    def process_task():
        """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰"""
        try:
            processor.process_file(
                file_path="test_small.txt",
                system_prompt="ë¶„ì„",
                user_prompt_template="{chunk_text}",
                model="claude-haiku-4",
                auto_confirm=True
            )
        except Exception as e:
            print(f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

    # ìŠ¤ë ˆë“œ ì‹œì‘
    print("ì²˜ë¦¬ ì‹œì‘...")
    thread = threading.Thread(target=process_task)
    thread.start()

    # 1ì´ˆ í›„ ì¼ì‹œì •ì§€
    time.sleep(1)
    print("\nì¼ì‹œì •ì§€ ìš”ì²­...")
    processor.request_pause()

    # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
    thread.join()

    print("\nì¼ì‹œì •ì§€ ì™„ë£Œ!")
    print("ë‚˜ì¤‘ì— ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ì¬ê°œ:")
    print("  python cli_processor.py resume test_small.txt")


def example_5_model_switching():
    """ì˜ˆì œ 5: ì²˜ë¦¬ ì¤‘ ëª¨ë¸ ë³€ê²½"""
    print("\n" + "="*70)
    print("ì˜ˆì œ 5: ì²˜ë¦¬ ì¤‘ ëª¨ë¸ ë³€ê²½")
    print("="*70)

    processor = IntegratedProcessor(api_client=None)

    # ì´ˆê¸° ìƒíƒœ í™•ì¸
    state = processor.file_processor.load_state("test_small.txt")

    if state is None:
        print("ë¨¼ì € ì²˜ë¦¬ë¥¼ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤:")
        print("  python cli_processor.py process test_small.txt")
        return

    print(f"í˜„ì¬ ëª¨ë¸: {state.current_model}")
    print(f"ì§„í–‰: {state.processed_chunks}/{state.total_chunks}")
    print(f"ëˆ„ì  ë¹„ìš©: ${state.total_cost:.4f}")

    # ëª¨ë¸ ë³€ê²½
    new_model = "gpt-4o-mini"
    print(f"\nëª¨ë¸ ë³€ê²½: {state.current_model} â†’ {new_model}")

    processor.file_processor.change_model(new_model)

    # ë‚¨ì€ ë¹„ìš© ì˜ˆì¸¡
    chunks = processor.preprocess_and_chunk("test_small.txt")
    remaining = processor.file_processor.estimate_remaining_cost(
        chunks, state.processed_chunks, new_model, 1000
    )

    print(f"ë‚¨ì€ ì˜ˆìƒ ë¹„ìš©: ${remaining['estimated_cost']:.4f}")
    print("\nì¬ê°œí•˜ë ¤ë©´:")
    print("  python cli_processor.py resume test_small.txt")


def example_6_batch_processing():
    """ì˜ˆì œ 6: ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬"""
    print("\n" + "="*70)
    print("ì˜ˆì œ 6: ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬")
    print("="*70)

    from pathlib import Path

    processor = IntegratedProcessor(api_client=None)

    # ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡
    files = [
        "document1.pdf",
        "document2.docx",
        "document3.txt"
    ]

    results_summary = []

    for file_path in files:
        if not Path(file_path).exists():
            print(f"â­ï¸  ê±´ë„ˆë›°ê¸°: {file_path} (íŒŒì¼ ì—†ìŒ)")
            continue

        print(f"\nğŸ“„ ì²˜ë¦¬ ì¤‘: {file_path}")

        try:
            state = processor.process_file(
                file_path=file_path,
                system_prompt="ìš”ì•½ ì „ë¬¸ê°€",
                user_prompt_template="ìš”ì•½: {chunk_text}",
                model="claude-haiku-4",
                output_tokens=500,
                auto_confirm=True
            )

            results_summary.append({
                'file': file_path,
                'chunks': state.processed_chunks,
                'cost': state.total_cost,
                'status': 'success'
            })

            # ê²°ê³¼ ì €ì¥
            output_file = f"results_{Path(file_path).stem}.json"
            processor.export_results(state, output_file)

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            results_summary.append({
                'file': file_path,
                'status': 'error',
                'error': str(e)
            })

    # ì „ì²´ ìš”ì•½
    print("\n" + "="*70)
    print("ì²˜ë¦¬ ìš”ì•½")
    print("="*70)

    total_cost = sum(r.get('cost', 0) for r in results_summary)
    success_count = sum(1 for r in results_summary if r['status'] == 'success')

    print(f"\nì´ {len(files)}ê°œ íŒŒì¼ ì¤‘ {success_count}ê°œ ì„±ê³µ")
    print(f"ì´ ë¹„ìš©: ${total_cost:.2f}")


def example_7_custom_chunking():
    """ì˜ˆì œ 7: ì»¤ìŠ¤í…€ ì²­í‚¹ ì „ëµ"""
    print("\n" + "="*70)
    print("ì˜ˆì œ 7: ì»¤ìŠ¤í…€ ì²­í‚¹ ì „ëµ")
    print("="*70)

    processor = IntegratedProcessor(api_client=None)

    # ì‹œë‚˜ë¦¬ì˜¤ 1: ì‘ì€ ì²­í¬ (ë” ì •í™•í•œ ì»¨í…ìŠ¤íŠ¸)
    print("\nì‹œë‚˜ë¦¬ì˜¤ 1: ì‘ì€ ì²­í¬ (50K ë¬¸ì)")
    chunks_small = processor.preprocess_and_chunk(
        "test_small.txt",
        chunk_size=50000,
        overlap=2000
    )
    print(f"  ì²­í¬ ìˆ˜: {len(chunks_small)}")

    # ì‹œë‚˜ë¦¬ì˜¤ 2: í° ì²­í¬ (ë¹„ìš© ì ˆê°)
    print("\nì‹œë‚˜ë¦¬ì˜¤ 2: í° ì²­í¬ (150K ë¬¸ì)")
    chunks_large = processor.preprocess_and_chunk(
        "test_small.txt",
        chunk_size=150000,
        overlap=5000
    )
    print(f"  ì²­í¬ ìˆ˜: {len(chunks_large)}")

    # ë¹„ìš© ë¹„êµ
    cost_small = len(chunks_small) * 0.01  # ì˜ˆìƒ ì²­í¬ë‹¹ ë¹„ìš©
    cost_large = len(chunks_large) * 0.01

    print(f"\në¹„ìš© ì˜ˆìƒ:")
    print(f"  ì‘ì€ ì²­í¬: ${cost_small:.2f}")
    print(f"  í° ì²­í¬: ${cost_large:.2f}")
    print(f"  ì ˆì•½: ${cost_small - cost_large:.2f}")


def example_8_result_analysis():
    """ì˜ˆì œ 8: ê²°ê³¼ ë¶„ì„ ë° í›„ì²˜ë¦¬"""
    print("\n" + "="*70)
    print("ì˜ˆì œ 8: ê²°ê³¼ ë¶„ì„")
    print("="*70)

    import json
    from pathlib import Path

    # ê²°ê³¼ íŒŒì¼ì´ ìˆë‹¤ê³  ê°€ì •
    result_file = "results.json"

    if not Path(result_file).exists():
        print(f"ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {result_file}")
        print("ë¨¼ì € íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  exportí•˜ì„¸ìš”.")
        return

    with open(result_file) as f:
        data = json.load(f)

    # ê¸°ë³¸ í†µê³„
    print("\nğŸ“Š ê¸°ë³¸ í†µê³„:")
    print(f"  íŒŒì¼: {data['file']}")
    print(f"  ëª¨ë¸: {data['model']}")
    print(f"  ì²˜ë¦¬ ì²­í¬: {data['processed_chunks']}/{data['total_chunks']}")
    print(f"  ì´ ë¹„ìš©: ${data['total_cost']:.2f}")

    # í† í° í†µê³„
    total_input = sum(r['input_tokens'] for r in data['results'])
    total_output = sum(r['output_tokens'] for r in data['results'])

    print(f"\nğŸ“ˆ í† í° ì‚¬ìš©:")
    print(f"  ì…ë ¥: {total_input:,} í† í°")
    print(f"  ì¶œë ¥: {total_output:,} í† í°")
    print(f"  í‰ê·  ì…ë ¥/ì²­í¬: {total_input // len(data['results']):,}")
    print(f"  í‰ê·  ì¶œë ¥/ì²­í¬: {total_output // len(data['results']):,}")

    # ë¹„ìš© ë¶„ì„
    avg_cost_per_chunk = data['total_cost'] / len(data['results'])

    print(f"\nğŸ’° ë¹„ìš© ë¶„ì„:")
    print(f"  ì²­í¬ë‹¹ í‰ê·  ë¹„ìš©: ${avg_cost_per_chunk:.4f}")
    print(f"  1MBë‹¹ ì˜ˆìƒ ë¹„ìš©: ${avg_cost_per_chunk * 100:.2f}")

    # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
    full_text = "\n\n---\n\n".join([
        f"## ì²­í¬ {r['chunk_index'] + 1}\n\n{r['response']}"
        for r in data['results']
    ])

    # ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì €ì¥
    output_md = "combined_results.md"
    with open(output_md, "w", encoding="utf-8") as f:
        f.write(f"# ì²˜ë¦¬ ê²°ê³¼: {Path(data['file']).name}\n\n")
        f.write(f"**ëª¨ë¸**: {data['model']}\n")
        f.write(f"**ë¹„ìš©**: ${data['total_cost']:.2f}\n\n")
        f.write("---\n\n")
        f.write(full_text)

    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_md}")


def main():
    """ë©”ì¸ ë©”ë‰´"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              ì‹¤ì „ ì‚¬ìš© ì˜ˆì œ ëª¨ìŒ                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    examples = {
        '1': ('ê°„ë‹¨í•œ ë¬¸ì„œ ìš”ì•½', example_1_simple_summary),
        '2': ('ë¹„ìš© ìµœì í™” ì „ëµ', example_2_cost_optimization),
        '3': ('ì ì§„ì  í’ˆì§ˆ í–¥ìƒ', example_3_progressive_quality),
        '4': ('ì¼ì‹œì •ì§€ ë° ì¬ê°œ', example_4_pause_resume),
        '5': ('ì²˜ë¦¬ ì¤‘ ëª¨ë¸ ë³€ê²½', example_5_model_switching),
        '6': ('ì—¬ëŸ¬ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬', example_6_batch_processing),
        '7': ('ì»¤ìŠ¤í…€ ì²­í‚¹ ì „ëµ', example_7_custom_chunking),
        '8': ('ê²°ê³¼ ë¶„ì„ ë° í›„ì²˜ë¦¬', example_8_result_analysis),
    }

    while True:
        print("\nì˜ˆì œ ì„ íƒ:")
        for key, (name, _) in examples.items():
            print(f"  {key}. {name}")
        print("  q. ì¢…ë£Œ")

        choice = input("\nì„ íƒ: ").strip().lower()

        if choice == 'q':
            print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if choice in examples:
            name, func = examples[choice]
            try:
                func()
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
        else:
            print("\nâŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")

        input("\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")


if __name__ == "__main__":
    main()
