"""
ëŒ€ìš©ëŸ‰ íŒŒì¼(31MB+) LLM ì²˜ë¦¬ ì‹œìŠ¤í…œ
- ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬
- ì§„í–‰ ìƒí™© ì €ì¥/ë³µì›
- ë¹„ìš© ì˜ˆì¸¡
- ì¼ì‹œì •ì§€/ì¬ê°œ ê¸°ëŠ¥
"""

import os
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime
import base64

@dataclass
class ProcessingState:
    """ì²˜ë¦¬ ìƒíƒœ ì €ì¥"""
    file_path: str
    file_hash: str
    total_chunks: int
    processed_chunks: int
    current_model: str
    total_cost: float
    results: List[Dict[str, Any]]
    created_at: str
    updated_at: str

    def to_dict(self):
        return asdict(self)

    @classmethod
    def from_dict(cls, data: dict):
        return cls(**data)


@dataclass
class ChunkInfo:
    """ì²­í¬ ì •ë³´"""
    index: int
    content_type: str  # 'text', 'image', 'mixed'
    text_content: Optional[str]
    image_data: Optional[List[Dict[str, Any]]]  # base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ì™€ ìœ„ì¹˜ ì •ë³´
    token_estimate: int
    original_position: int  # ì›ë³¸ íŒŒì¼ì—ì„œì˜ ìœ„ì¹˜


class ModelPricing:
    """ëª¨ë¸ë³„ ê°€ê²© ì •ë³´ (1M í† í° ê¸°ì¤€)"""
    MODELS = {
        'claude-sonnet-4-5': {'input': 3.00, 'output': 15.00},
        'claude-sonnet-4': {'input': 3.00, 'output': 15.00},
        'claude-opus-4': {'input': 15.00, 'output': 75.00},
        'claude-haiku-4': {'input': 0.80, 'output': 4.00},
        'gpt-4o': {'input': 2.50, 'output': 10.00},
        'gpt-4o-mini': {'input': 0.15, 'output': 0.60},
    }

    @classmethod
    def estimate_cost(cls, model: str, input_tokens: int, output_tokens: int) -> float:
        """ë¹„ìš© ì˜ˆì¸¡"""
        if model not in cls.MODELS:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model}")

        pricing = cls.MODELS[model]
        cost = (input_tokens / 1_000_000 * pricing['input'] +
                output_tokens / 1_000_000 * pricing['output'])
        return cost

    @classmethod
    def compare_models(cls, input_tokens: int, output_tokens: int) -> Dict[str, float]:
        """ëª¨ë“  ëª¨ë¸ì˜ ë¹„ìš© ë¹„êµ"""
        return {
            model: cls.estimate_cost(model, input_tokens, output_tokens)
            for model in cls.MODELS.keys()
        }


class LargeFileProcessor:
    """ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, state_dir: str = "./processing_states"):
        self.state_dir = Path(state_dir)
        self.state_dir.mkdir(exist_ok=True)
        self.current_state: Optional[ProcessingState] = None

    def calculate_file_hash(self, file_path: str) -> str:
        """íŒŒì¼ í•´ì‹œ ê³„ì‚° (ì§„í–‰ ìƒí™© ì‹ë³„ìš©)"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    def estimate_tokens(self, text: str, images: int = 0) -> int:
        """í† í° ìˆ˜ ì˜ˆì¸¡ (ëŒ€ëµì )"""
        # í…ìŠ¤íŠ¸: 1 í† í° â‰ˆ 4ì (ì˜ì–´ ê¸°ì¤€)
        # í•œê¸€: 1 í† í° â‰ˆ 1.5ì
        text_tokens = len(text) // 2  # ë³´ìˆ˜ì  ì¶”ì •
        # ì´ë¯¸ì§€: ì•½ 1000-2000 í† í°/ì´ë¯¸ì§€
        image_tokens = images * 1500
        return text_tokens + image_tokens

    def create_chunks(self,
                     file_path: str,
                     chunk_size: int = 100000,  # ì•½ 50k í† í°
                     overlap: int = 5000) -> List[ChunkInfo]:
        """
        íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í• 

        Args:
            file_path: íŒŒì¼ ê²½ë¡œ
            chunk_size: ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)
            overlap: ì²­í¬ ê°„ ê²¹ì¹¨ (ë¬¸ë§¥ ìœ ì§€)
        """
        # ì´ ë©”ì„œë“œëŠ” íŒŒì¼ í˜•ì‹ì— ë”°ë¼ ì˜¤ë²„ë¼ì´ë“œ í•„ìš”
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ íŒŒì¼ ì²˜ë¦¬
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        chunks = []
        start = 0
        index = 0

        while start < len(content):
            end = start + chunk_size
            chunk_text = content[start:end]

            chunks.append(ChunkInfo(
                index=index,
                content_type='text',
                text_content=chunk_text,
                image_data=None,
                token_estimate=self.estimate_tokens(chunk_text),
                original_position=start
            ))

            start = end - overlap
            index += 1

        return chunks

    def save_state(self, state: ProcessingState):
        """ì§„í–‰ ìƒí™© ì €ì¥"""
        state_file = self.state_dir / f"{state.file_hash}.json"
        state.updated_at = datetime.now().isoformat()

        with open(state_file, 'w', encoding='utf-8') as f:
            json.dump(state.to_dict(), f, indent=2, ensure_ascii=False)

        print(f"âœ“ ì§„í–‰ ìƒí™© ì €ì¥ë¨: {state_file}")

    def load_state(self, file_path: str) -> Optional[ProcessingState]:
        """ì €ì¥ëœ ì§„í–‰ ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸°"""
        file_hash = self.calculate_file_hash(file_path)
        state_file = self.state_dir / f"{file_hash}.json"

        if not state_file.exists():
            return None

        with open(state_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        return ProcessingState.from_dict(data)

    def initialize_processing(self,
                            file_path: str,
                            model: str = 'claude-haiku-4') -> ProcessingState:
        """ì²˜ë¦¬ ì´ˆê¸°í™”"""
        file_hash = self.calculate_file_hash(file_path)

        # ê¸°ì¡´ ìƒíƒœ í™•ì¸
        existing_state = self.load_state(file_path)
        if existing_state:
            print(f"ğŸ“‚ ê¸°ì¡´ ì§„í–‰ ìƒí™© ë°œê²¬: {existing_state.processed_chunks}/{existing_state.total_chunks} ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ")
            print(f"   í˜„ì¬ ëª¨ë¸: {existing_state.current_model}")
            print(f"   ëˆ„ì  ë¹„ìš©: ${existing_state.total_cost:.4f}")

            response = input("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
            if response.lower() == 'y':
                self.current_state = existing_state
                return existing_state

        # ìƒˆë¡œìš´ ì²˜ë¦¬ ì‹œì‘
        print("ğŸ“„ íŒŒì¼ ì²­í¬ ë¶„í•  ì¤‘...")
        chunks = self.create_chunks(file_path)

        state = ProcessingState(
            file_path=file_path,
            file_hash=file_hash,
            total_chunks=len(chunks),
            processed_chunks=0,
            current_model=model,
            total_cost=0.0,
            results=[],
            created_at=datetime.now().isoformat(),
            updated_at=datetime.now().isoformat()
        )

        self.current_state = state
        self.save_state(state)

        return state

    def estimate_remaining_cost(self,
                               chunks: List[ChunkInfo],
                               start_index: int,
                               model: str,
                               output_tokens_per_chunk: int = 1000) -> Dict[str, Any]:
        """ë‚¨ì€ ì²˜ë¦¬ ë¹„ìš© ì˜ˆì¸¡"""
        remaining_chunks = chunks[start_index:]
        total_input_tokens = sum(chunk.token_estimate for chunk in remaining_chunks)
        total_output_tokens = len(remaining_chunks) * output_tokens_per_chunk

        cost = ModelPricing.estimate_cost(model, total_input_tokens, total_output_tokens)

        # ë‹¤ë¥¸ ëª¨ë¸ê³¼ ë¹„êµ
        model_comparison = ModelPricing.compare_models(total_input_tokens, total_output_tokens)

        return {
            'remaining_chunks': len(remaining_chunks),
            'input_tokens': total_input_tokens,
            'output_tokens': total_output_tokens,
            'estimated_cost': cost,
            'model_comparison': model_comparison
        }

    def change_model(self, new_model: str):
        """ì²˜ë¦¬ ì¤‘ ëª¨ë¸ ë³€ê²½"""
        if self.current_state is None:
            raise ValueError("ì²˜ë¦¬ ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        old_model = self.current_state.current_model
        self.current_state.current_model = new_model
        self.save_state(self.current_state)

        print(f"ğŸ”„ ëª¨ë¸ ë³€ê²½: {old_model} â†’ {new_model}")


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    processor = LargeFileProcessor()

    # ë¹„ìš© ì˜ˆì¸¡ ì˜ˆì œ
    print("\n" + "="*60)
    print("ëª¨ë¸ë³„ ë¹„ìš© ë¹„êµ (100ë§Œ ì…ë ¥ í† í°, 10ë§Œ ì¶œë ¥ í† í°)")
    print("="*60)
    comparison = ModelPricing.compare_models(1_000_000, 100_000)
    for model, cost in sorted(comparison.items(), key=lambda x: x[1]):
        print(f"{model:25s}: ${cost:8.2f}")
