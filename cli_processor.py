#!/usr/bin/env python3
"""
ëŒ€ìš©ëŸ‰ íŒŒì¼ LLM ì²˜ë¦¬ CLI ë„êµ¬

ì‚¬ìš©ë²•:
    python cli_processor.py process document.pdf --prompt "ìš”ì•½í•´ì£¼ì„¸ìš”"
    python cli_processor.py resume document.pdf
    python cli_processor.py status
    python cli_processor.py export results.json
"""

import argparse
import sys
import signal
from pathlib import Path

from integrated_processor import IntegratedProcessor


class CLIProcessor:
    """CLI ì¸í„°í˜ì´ìŠ¤"""

    def __init__(self):
        self.processor = IntegratedProcessor()

        # Ctrl+C í•¸ë“¤ëŸ¬ ë“±ë¡
        signal.signal(signal.SIGINT, self._signal_handler)

    def _signal_handler(self, signum, frame):
        """Ctrl+C ì²˜ë¦¬"""
        print("\n\nâš ï¸  ì¤‘ë‹¨ ì‹ í˜¸ ê°ì§€ (Ctrl+C)")
        print("ì§„í–‰ ì¤‘ì¸ ì²­í¬ ì²˜ë¦¬ë¥¼ ì™„ë£Œí•œ í›„ ì¼ì‹œì •ì§€í•©ë‹ˆë‹¤...")
        self.processor.request_pause()

    def process(self, args):
        """íŒŒì¼ ì²˜ë¦¬ ì‹œì‘"""
        # API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        api_client = self._setup_api_client(args.api, args.api_key)
        self.processor.api_client = api_client

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = args.system_prompt or "ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."

        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        user_prompt = args.prompt or "ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{chunk_text}"

        # ì²˜ë¦¬ ì‹¤í–‰
        state = self.processor.process_file(
            file_path=args.file,
            system_prompt=system_prompt,
            user_prompt_template=user_prompt,
            model=args.model,
            output_tokens=args.max_output,
            auto_confirm=args.yes
        )

        # ê²°ê³¼ ì¶œë ¥
        if args.output:
            self.processor.export_results(state, args.output)

    def resume(self, args):
        """ì¤‘ë‹¨ëœ ì²˜ë¦¬ ì¬ê°œ"""
        # ìƒíƒœ í™•ì¸
        state = self.processor.file_processor.load_state(args.file)

        if state is None:
            print(f"âŒ '{args.file}'ì— ëŒ€í•œ ì €ì¥ëœ ìƒíƒœë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   ì²˜ìŒë¶€í„° ì‹œì‘í•˜ë ¤ë©´ 'process' ëª…ë ¹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
            return

        print(f"\nğŸ“‚ ì €ì¥ëœ ìƒíƒœ ë¡œë“œ")
        print(f"   íŒŒì¼: {state.file_path}")
        print(f"   ì§„í–‰: {state.processed_chunks}/{state.total_chunks} ì²­í¬")
        print(f"   ëª¨ë¸: {state.current_model}")
        print(f"   ëˆ„ì  ë¹„ìš©: ${state.total_cost:.4f}")

        # ëª¨ë¸ ë³€ê²½ ì˜µì…˜
        if args.model and args.model != state.current_model:
            print(f"\nğŸ”„ ëª¨ë¸ ë³€ê²½: {state.current_model} â†’ {args.model}")
            self.processor.file_processor.change_model(args.model)

        # API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        api_client = self._setup_api_client(args.api, args.api_key)
        self.processor.api_client = api_client

        # ì²­í¬ ë¡œë“œ
        chunks = self.processor.preprocess_and_chunk(args.file)

        # ì²˜ë¦¬ ì¬ê°œ
        print("\nâ–¶ï¸  ì²˜ë¦¬ ì¬ê°œ...")
        self.processor._process_chunks(
            chunks=chunks,
            state=state,
            system_prompt=args.system_prompt or "ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
            user_prompt_template=args.prompt or "ë‹¤ìŒ ë‚´ìš©ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:\n\n{chunk_text}",
            model=state.current_model,
            output_tokens=args.max_output
        )

        # ê²°ê³¼ ì¶œë ¥
        if args.output:
            self.processor.export_results(state, args.output)

    def status(self, args):
        """ì²˜ë¦¬ ìƒíƒœ í™•ì¸"""
        state_files = list(self.processor.file_processor.state_dir.glob("*.json"))

        if not state_files:
            print("ì €ì¥ëœ ì²˜ë¦¬ ìƒíƒœê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"\n{'='*70}")
        print(f"ì €ì¥ëœ ì²˜ë¦¬ ìƒíƒœ: {len(state_files)}ê°œ")
        print(f"{'='*70}\n")

        for state_file in state_files:
            with open(state_file, 'r') as f:
                import json
                state_data = json.load(f)

            progress = (state_data['processed_chunks'] / state_data['total_chunks'] * 100)

            print(f"ğŸ“„ {Path(state_data['file_path']).name}")
            print(f"   ì§„í–‰: {state_data['processed_chunks']}/{state_data['total_chunks']} ({progress:.1f}%)")
            print(f"   ëª¨ë¸: {state_data['current_model']}")
            print(f"   ë¹„ìš©: ${state_data['total_cost']:.4f}")
            print(f"   ì—…ë°ì´íŠ¸: {state_data['updated_at'][:19]}")
            print()

    def export(self, args):
        """ê²°ê³¼ ë‚´ë³´ë‚´ê¸°"""
        if not args.file:
            print("âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”.")
            return

        state = self.processor.file_processor.load_state(args.file)
        if state is None:
            print(f"âŒ '{args.file}'ì— ëŒ€í•œ ì €ì¥ëœ ìƒíƒœë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        output_path = args.output or f"results_{Path(args.file).stem}.json"
        self.processor.export_results(state, output_path)

    def _setup_api_client(self, api_type: str, api_key: str = None):
        """API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •"""
        if api_type == 'anthropic':
            try:
                from anthropic import Anthropic

                if api_key is None:
                    import os
                    api_key = os.getenv('ANTHROPIC_API_KEY')

                if not api_key:
                    print("âš ï¸  ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    print("   ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
                    return None

                return Anthropic(api_key=api_key)

            except ImportError:
                print("âŒ anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                print("   pip install anthropic")
                sys.exit(1)

        elif api_type == 'openai':
            try:
                from openai import OpenAI

                if api_key is None:
                    import os
                    api_key = os.getenv('OPENAI_API_KEY')

                if not api_key:
                    print("âš ï¸  OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    print("   ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
                    return None

                return OpenAI(api_key=api_key)

            except ImportError:
                print("âŒ openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                print("   pip install openai")
                sys.exit(1)

        else:
            print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” API íƒ€ì…: {api_type}")
            print("   ë°ëª¨ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
            return None


def main():
    parser = argparse.ArgumentParser(
        description='ëŒ€ìš©ëŸ‰ íŒŒì¼ LLM ì²˜ë¦¬ ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì œ:
  # ìƒˆ íŒŒì¼ ì²˜ë¦¬
  %(prog)s process document.pdf --prompt "ìš”ì•½í•´ì£¼ì„¸ìš”" --model claude-haiku-4

  # ì¤‘ë‹¨ëœ ì²˜ë¦¬ ì¬ê°œ
  %(prog)s resume document.pdf

  # ë‹¤ë¥¸ ëª¨ë¸ë¡œ ë³€ê²½í•˜ì—¬ ì¬ê°œ
  %(prog)s resume document.pdf --model gpt-4o-mini

  # ì²˜ë¦¬ ìƒíƒœ í™•ì¸
  %(prog)s status

  # ê²°ê³¼ ë‚´ë³´ë‚´ê¸°
  %(prog)s export document.pdf --output results.json
        """
    )

    subparsers = parser.add_subparsers(dest='command', help='ëª…ë ¹')

    # process ëª…ë ¹
    process_parser = subparsers.add_parser('process', help='ìƒˆ íŒŒì¼ ì²˜ë¦¬')
    process_parser.add_argument('file', help='ì²˜ë¦¬í•  íŒŒì¼')
    process_parser.add_argument('--prompt', '-p', help='LLM í”„ë¡¬í”„íŠ¸')
    process_parser.add_argument('--system-prompt', help='ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸')
    process_parser.add_argument('--model', '-m', default='claude-haiku-4',
                               help='ì‚¬ìš©í•  ëª¨ë¸ (ê¸°ë³¸: claude-haiku-4)')
    process_parser.add_argument('--max-output', type=int, default=1000,
                               help='ìµœëŒ€ ì¶œë ¥ í† í° (ê¸°ë³¸: 1000)')
    process_parser.add_argument('--api', choices=['anthropic', 'openai'],
                               default='anthropic', help='API ì œê³µì')
    process_parser.add_argument('--api-key', help='API í‚¤')
    process_parser.add_argument('--output', '-o', help='ê²°ê³¼ ì €ì¥ ê²½ë¡œ')
    process_parser.add_argument('--yes', '-y', action='store_true',
                               help='ë¹„ìš© í™•ì¸ ì—†ì´ ë°”ë¡œ ì‹¤í–‰')

    # resume ëª…ë ¹
    resume_parser = subparsers.add_parser('resume', help='ì¤‘ë‹¨ëœ ì²˜ë¦¬ ì¬ê°œ')
    resume_parser.add_argument('file', help='ì¬ê°œí•  íŒŒì¼')
    resume_parser.add_argument('--model', '-m', help='ëª¨ë¸ ë³€ê²½')
    resume_parser.add_argument('--prompt', '-p', help='LLM í”„ë¡¬í”„íŠ¸')
    resume_parser.add_argument('--system-prompt', help='ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸')
    resume_parser.add_argument('--max-output', type=int, default=1000,
                               help='ìµœëŒ€ ì¶œë ¥ í† í°')
    resume_parser.add_argument('--api', choices=['anthropic', 'openai'],
                               default='anthropic', help='API ì œê³µì')
    resume_parser.add_argument('--api-key', help='API í‚¤')
    resume_parser.add_argument('--output', '-o', help='ê²°ê³¼ ì €ì¥ ê²½ë¡œ')

    # status ëª…ë ¹
    status_parser = subparsers.add_parser('status', help='ì²˜ë¦¬ ìƒíƒœ í™•ì¸')

    # export ëª…ë ¹
    export_parser = subparsers.add_parser('export', help='ê²°ê³¼ ë‚´ë³´ë‚´ê¸°')
    export_parser.add_argument('file', nargs='?', help='íŒŒì¼')
    export_parser.add_argument('--output', '-o', help='ì¶œë ¥ ê²½ë¡œ')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    cli = CLIProcessor()

    if args.command == 'process':
        cli.process(args)
    elif args.command == 'resume':
        cli.resume(args)
    elif args.command == 'status':
        cli.status(args)
    elif args.command == 'export':
        cli.export(args)


if __name__ == '__main__':
    main()
